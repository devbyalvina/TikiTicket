## 동시성 문제 해결하기

### DB에서의 동시성 제어 문제란

- 같은 데이터에 대해 동시에 조작하려고 할 때 발생
- 같은 데이터에 대해 어떤 트랜잭션이 **처리되는 중간에 다른 트랜잭션**이 끼어들어 발생하는 데이터 정합성 문제
- **해결방안**: 한 트랜잭션이 끝나면 다른 트랜잭션이 처리되도록 구현  
  
<br/>

### 동시성 제어 문제 해결 시 고려사항

1. **비지니스 및 시스템 구조**
- 비지니스 및 시스템 구조에 따라 락 종류 별로 발생하는 충돌, 데드락과 같은 오버헤드 발생 빈도, 지속 시간을 고려
- 비지니스에서 요구되는 데이터 정합성 수준도 고려
2. **트랜잭션의 범위**
- 트랜잭션의 범위가 커지면 롤백을 위해 홀딩하는 UNDO 로그의 범위가 커져서 성능상 불리함  
- 트랜잭션 범위가 넓어지면 복잡성 증가로 락을 여러 테이블 or 여러 로우에 걸면서 충돌/데드락 발생할 가능성 더 높아짐  
3. **순서보장 요구사항**  
- 동시에 ‘여러 개’의 트랜잭션이 발생하는 상황  
- 순서 상관없이 하나씩만 처리되도록 격리만 시키면 되는지, 지켜야 하는 순서가 있는지에 대한 요구사항에 따라 선택 가능한 해결책이 달라짐

<br/>

### 동시성 제어문제 해결방안

- **DB락**
    - 낙관적락 vs 비관적락 선택기준  
        ⇒ 충돌: 자주 발생X → 낙관적락을 선택
    - 데드락: 비관적락을 넓은 범위로 사용할 경우 발생 가능

- **Redis 분산락**
    
    **장점**
    
    - 캐시: 물리적 디스크에 쓰는 것보다 처리속도 훨씬 빠름
    - Key-Value
    - 싱글 스레드: 순서 보장 가능
    
    **단점**
    
    - 휘발성: 레디스 서버가 죽으면 데이터 다 날라감
    - SPOF 가능성: 레디스 서버가 죽으면 서버는 대규모 트래픽에 그대로 노출
    
    **종류**
    
    - **Simple 락** - 1번 try
    - **Spin 락** - N번 try
        
        **단점**
        
        - 재시도 횟수에 대한 정책과 재시도 로직 구현이 필요
        - 폴링 방식의 비효율성
    - **Pub/Sub 락**
        
        **장점**
        
        - Lock 획득 재시도 최소화
        
        **단점**
        
        - 수신확인 X, 전송보장 X: Subscriber가 없으면 이벤트도 사라진다.
    
    **영속화 하기 위한 방법**
    
    - write back: 일정 시간 간격으로 저장
    - write through: 무조건 저장
    - write around: cache miss 발생하는 경우에만 저장

- **Kafka**
    
    **장점**
    
    - 큐 ⇒ 단일 파티션 내에서는 동시성 문제 발생X, 순서 보장
    
    **단점**
    
    - 파티션 안에서 밀리면 느려짐, 파티션 줄이기가 어려움
    - 컨슈머 처리 속도가 달라질 수 있어 동시성 문제 발생 가능 (엄밀히 말하면 DB 동시성 문제 해결 방안은 아님)   
      따라서 컨슈머에서 추가적인 동시성 문제 제어 로직 구현 필요
        
<br/>

### 프로젝트에서 발생하는 동시성 문제 해결책

1. **좌석 선점 문제**

- **DB 락:** **`사용 OK`** **`(비관적락)`**
  
    - 내가 정의한 좌석 예매좌석은 지정 좌석 예매임 (좌석 마다 각각 id를 땀, 재고 개념X)
    - 그냥 ‘예매’ 프로세스 상에서는 최초 1명만 성공시키고 나머진 다 실패 시킬거기 때문에 낙관적락이 적절해 보일 수 있음
    - 하지만 내가 구현한 함수는 ‘좌석 상태 변경’으로, 추가 요구사항이 (**예 -** 예매 취소) 발생하면 충돌이 많이 발생하여 낙관적락으로 제어 불가.

    ```
    TR1 User01 예매취소 시작 [version1 이었음] → TR2 User02 예매 [version1을 찾음]
    → TR1 User01 예매취소 끝 [version2로 업데이트] → TR2 User02 예매 [version1을 찾으니 실패]
    → TR3 User03 예매 시작[version2를 찾음]/끝[version3으로 바꿈] 
    
    ⇒ 'TR2'가 'TR3' 보다 먼저왔는데 예약 못함
    ```    
    
    - 그냥 깔끔하게 비관적락 사용하고 조회에 대한 부하를 줄이고 싶다면 CQRS로 읽기/쓰기 분리할 것  
      - MVCC에서는 비관적락 사용해도 조회는 됨
      - 하지만 조회로 인한 부하를 줄이기 위해 CQRS 고려
      - 특히 콘서트 정보의 경우 자주 변경X - 캐시를 사용하면 유리할 것으로 예상됨
    - 다만 트래픽이 엄청나게 증가할 경우 업데이트 요청으로 인한 과도한 DB Access 부하 발생 가능
      
- **Redis 분산락:** **`사용 OK`**
    - 트래픽이 엄청나게 증가할 경우 DB 병목 현상을 줄일 수 있음
      
- **Kafka**: **`사용 X`**
    - 앞에서 레디스로 구현한 대기열로 유량 제어가 되어 들어오고, 추가로 큐를 사용할 필요는 없어서 사용 안 함
    - 특히 카프카는 파티션 단위로 부하 분산이 가능한 점이 이점인데, 여기서는 점유하고자 하는 자원이 1개이므로 파티션 단위의 부하 분산이 의미 없다고 판단 됨

<br/>

2. **포인트 사용**

- **DB 락:** **`사용 OK`** **`(비관적락)`**
    - 낙관적락은 한 트랜잭션 처리 도중 읽기가 가능하므로 정합성 문제 발생 가능  
    - 한 트랜잭션이 진행 중인 경우 다음 트랜잭션은 실패시키는게 아니라 기다렸다가 진행시켜야 하므로 낙관적락을 사용하면 재시도 로직 구현이 필요, 로직 구현의 복잡도 증가  
    (그냥 실패 시켜버리면 사용자 경험이 저하됨)
- **Redis 분산락:** **`사용 OK`**
    - 트래픽이 엄청나게 증가할 경우 DB 병목 현상을 줄일 수 있음
- **Kafka:** **`사용 OK`**
    - 트래픽이 엄청나게 증가할 경우 파티션을 통한 부하분산 가능
    - 순서 보장, 로그 등 포인트 비지니스에 필요한 기능 제공
        - 순서 보장: 유저 별 순서만 유지되면 됨 ⇒ 같은 유저의 요청 이벤트는 같은 파티션 사용
        - 로그: 실패해도 재처리 가능  
    - 컨슈머에서 추가적인 동시성 문제 처리 필요
